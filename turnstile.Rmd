---
title: "Analyzing MTA Turnstile data"
date: "April 2020"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This markdown is to explain how to analyze turnstile data from the MTA website in R. 

Data can be found here: http://web.mta.info/developers/turnstile.html. 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)

mta <- read_csv("~/interactives/mta_turnstile/data/mta_example14st.csv") 
# This is just a shortened file only including 14th Street Union Square. You can find the full one in  /data. 
```

Begin by loading the necessary libraries and reading in the data. I'm using the tidyverse packages for most of the analysis so that code looks different from base R. Next I'm going to clean up the data a bit. 

Let's take a look at the whole data frame. 

```{r}
str(mta)
```

We're going to need to reformat the date. 

``` {r}
mta$DATE[2]

mta_date <- as.character.Date(mta$DATE) %>% str_sub(1,10)
mta_time <- as.character(mta$TIME) %>% str_sub(12,21)
mta_dt <- paste(mta_date,"T",mta_time, sep = "") %>% lubridate::ymd_hms()

mta$date_time <- mta_dt
mta$just_date <- mta_date
mta$just_time <- mta_time

mta$date_time[2]
```

New look, same great taste.

When you look at "ENTRIES" you see that they're not starting from 0 so we're going to fix that. 

``` {r}
head(mta$ENTRIES, 12)

# Create new column "new.entries" and "new.exits" 
# calculated from cumulative "ENTRIES"/"EXITS" for each station
new_entries <- vector(length = nrow(mta))
new_exits <- vector(length = nrow(mta))
new_scp <- vector(length = nrow(mta)) # new_scp indicates device ID (dif turnstile?)
for (i in 1:nrow(mta)) {
  new_entries[i] <- mta$ENTRIES[i+1] - mta$ENTRIES[i]
  new_exits[i] <- mta$EXITS[i+1] - mta$EXITS[i]
  new_scp[i] <- mta$SCP[i+1] != mta$SCP[i]
}

mta$new_entries <- new_entries # Not the same as "ENTRIES" 
mta$new_exits <- new_exits
new_scp[1] <- TRUE
mta$new_scp <- new_scp

head(mta, 2)
```
I need to add an explanation of what I'm doing ^here. 

```{r}
mta_cleanr <- mta %>%
  filter(new_scp == F) %>% 
  select(date_time,STATION, LINENAME, SCP, ENTRIES, new_entries, new_exits, just_date, just_time)
head(mta_cleanr, 10)
# write_csv(mta_cleanr, "~/interactives/mta_turnstile/data/export/mta_clean.csv")
# I did this on my computer with the whole file. i'll use this later. 
```

I have a the data in a form I can use now.

``` {r}
#overwriting the above file to access the whole file (it's big af)
mta_cleanr <- read_csv("~/interactives/mta_turnstile/data/export/mta_clean.csv")
mta_cleanr
#This will take the total rides per day and the average rides every four hours. 
mta_perday <-
  mta_cleanr %>%
  group_by(station_name, date) %>%
  summarise(avg_entries = mean(entries), # avg is four each unit of time data was collected, four hours
            total_entries = sum(entries),
            avg_exits = mean(exits),
            total_exits = sum(exits)) %>%
  filter(date != "1899-12-31") # This date gets included for some reason
head(mta_perday, 10)
```

Time to graph it. 
```{r}
mta_perday %>% filter(station_name == "14 ST-UNION SQ") %>%
  mutate(month_day = str_sub(date, 6,10)) %>%
  ggplot(aes(x = month_day, y = total_entries)) +
  geom_bar(stat = "identity") +
  ylab("Daily turnstiles entries") + xlab("Date") + 
  ggtitle("Total daily turnstile entries at 14-Street Union Sq.") +
  coord_flip() 
```

Now I'm going to combine the the income-geolocated data from Sam. Also going to read in the full cleaned up data, mta_cleanr. (I just did this to save time compiling on my computer)

```{r}
geo_income <- read_csv("~/interactives/mta_turnstile/data/2018-med-income-ACS_by_subway-station - 2018-med-income-ACS_by_subway-station.csv")
geo_income$income <- geo_income$ct_median_income_2018_ACS %>% 
  str_remove("[:punct:]") %>%
  str_sub(2) %>%
  as.numeric()
```
Let's compare the two data sets we're working with rn. 

```{r paged.print=TRUE}
head(select(geo_income, -the_geom)) #left out one column for mapping
head(mta_perday)
```

I'm going to want to combine the data by station name so let's compare the names in both data frames.

```{r}
mta_stations <- mta_cleanr$station_name %>% unique %>% data_frame(station_name=.) 
geo_station <- geo_income$station_name %>% unique %>% data_frame(station_name=.)
both_station_names <- c(mta_stations$station_name, geo_station$station_name) %>% sort()
both_station_names
```

Most of them look the same but a lot are different. 
Let's look at stations that include "PARKSIDE".

```{r}
both_station_names[str_which(both_station_names, "PARKSIDE")] 
```

First I'm going to change all the "AV"s to "AVE"s. in the mta_cleanr dataset. But I need to make sure not to turn "AVE" into "AVEE" (because it already has an "AV" inside).This is makes it a little harder. 

```{r}
#need to switch "av" to "ave" in mta data. idk why this is so hard.
# First we need to check how "av" is written and not correct the "aves"
mta_cleanr$ave_true <- FALSE
mta_cleanr$ave_true[str_which(mta_cleanr$station_name, "AVE")] <- TRUE
mta_cleanr$av_true <- FALSE
mta_cleanr$av_true[str_which(mta_cleanr$station_name, "AV")] <- TRUE 
mta_cleanr$av_not_ave <- FALSE
mta_cleanr$av_not_ave[which(mta_cleanr$av_true == TRUE & mta_cleanr$ave_true == FALSE)] <- TRUE
mta_cleanr$station_name[mta_cleanr$av_not_ave == T] <-
  str_replace_all(mta_cleanr$station_name[mta_cleanr$av_not_ave == T], "AV", "AVE")
mta_cleanr %>% 
  slice(str_which(mta_cleanr$station_name, "AVE")) %>% 
  select(date_time, station_name) %>% 
  sample_n(20)
```
Let's take a peak at our product
```{r}
mta_cleanr %>% 
  slice(str_which(mta_cleanr$station_name, "AVE")) %>% 
  select(date_time, station_name) %>% 
  sample_n(20)
```
Looks good. Now I'm going to join the MTA turnstile data with the geo-income data. Not all of is going to join correctly so I'll make a dataframe for the whole messy product, just the ones that did join, and just the ones that didn't. 

```{r}
mta_geo_messy <- full_join(x = mta_cleanr %>% select(date_time, station_name, train_lines, entries, exits, date, time, scp),
                           y = geo_income %>% select(station_name, borough,train_lines, long, lat, income, service, unit), 
                           by = c("station_name","train_lines"))
mta_geo <- mta_geo_messy %>% filter(!is.na(income) & !is.na(entries))
mta_geo_unjoined <- mta_geo_messy %>% filter(is.na(income) | is.na(entries))
sample_n(mta_geo_unjoined, 20)
```

Now we've got a starting point for the turnstile data with geo-income. We're probably going to have to go back and fix the unjoined data. 

Based on the above graph there's a huge drop between February and March. I'm going to compare the 27th of each month. 

```{r}
mtageo_day <- mta_geo_messy %>% 
  group_by(date, station_name, train_lines) %>%
  summarise(total_entries = sum(entries), 
            total_exits = sum(exits),
            income = income[1], 
            long= long[1], 
            lat = lat[1]) %>%
  filter(date == "2020-02-27" | date == "2020-03-27") %>% # We're going to compare these two days
  filter(!is.na(income) & !is.na(long) & !is.na(lat)) %>%
  arrange(station_name)
head(mtageo_day)
```

What I want to do next is turn february and march into separate columns and then take the difference.
```{r}
mta_daydif <- mtageo_day %>%  pivot_wider(names_from = date, values_from = c(total_entries, total_exits)) 
colnames(mta_daydif)  <- colnames(mta_daydif) %>% str_replace_all("-","_")  
head(mta_daydif,6)
```
Now we can calculate the difference for entries and exits. 
```{r}
mta_daydif <- mta_daydif %>% mutate(entry_dif = total_entries_2020_02_27 - total_entries_2020_03_27, 
                                    exit_dif = total_exits_2020_02_27 - total_exits_2020_03_27) %>%
  select(-c(total_entries_2020_02_27:total_exits_2020_03_27))
head(mta_daydif)
```

Let's try graphing. It's supposed to make the size based on entries and the color based on income. 

```{r}
ggplot(mta_daydif) + geom_point(aes(x=long, y = lat, size = entry_dif, color = income, alpha = .1)) + 
  theme(legend.position = "none")
```

It's not what we want but it's a start. 

